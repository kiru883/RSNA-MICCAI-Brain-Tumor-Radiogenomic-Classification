{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc5ab9ec",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-09-22T21:50:18.967731Z",
     "iopub.status.busy": "2021-09-22T21:50:18.967001Z",
     "iopub.status.idle": "2021-09-22T21:50:22.941797Z",
     "shell.execute_reply": "2021-09-22T21:50:22.940989Z",
     "shell.execute_reply.started": "2021-09-22T19:48:02.963603Z"
    },
    "papermill": {
     "duration": 3.99386,
     "end_time": "2021-09-22T21:50:22.941979",
     "exception": false,
     "start_time": "2021-09-22T21:50:18.948119",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydicom \n",
    "import math\n",
    "import cv2\n",
    "import gc\n",
    "import glob\n",
    "import re\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import torchmetrics\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pydicom.pixel_data_handlers.util import apply_voi_lut\n",
    "\n",
    "IMAGE_SIZE = 256\n",
    "NUM_IMAGES = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc8a6d65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-22T21:50:22.956881Z",
     "iopub.status.busy": "2021-09-22T21:50:22.956121Z",
     "iopub.status.idle": "2021-09-22T21:50:23.139668Z",
     "shell.execute_reply": "2021-09-22T21:50:23.140342Z",
     "shell.execute_reply.started": "2021-09-22T19:48:08.616811Z"
    },
    "papermill": {
     "duration": 0.192654,
     "end_time": "2021-09-22T21:50:23.140538",
     "exception": false,
     "start_time": "2021-09-22T21:50:22.947884",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Functions\n",
    "\n",
    "def load_dicom_image(path, img_size=IMAGE_SIZE, voi_lut=True, rotate=0):\n",
    "    dicom = pydicom.read_file(path)\n",
    "    data = dicom.pixel_array\n",
    "    if voi_lut:\n",
    "        data = apply_voi_lut(dicom.pixel_array, dicom)\n",
    "    else:\n",
    "        data = dicom.pixel_array\n",
    "        \n",
    "    if rotate > 0:\n",
    "        rot_choices = [0, cv2.ROTATE_90_CLOCKWISE, cv2.ROTATE_90_COUNTERCLOCKWISE, cv2.ROTATE_180]\n",
    "        data = cv2.rotate(data, rot_choices[rotate])\n",
    "        \n",
    "    data = cv2.resize(data, (img_size, img_size))\n",
    "    return data\n",
    "\n",
    "\n",
    "def load_dicom_images_3d(path, num_imgs=NUM_IMAGES, img_size=IMAGE_SIZE, rotate=0):\n",
    "    files = sorted(glob.glob(f\"{path}/*.dcm\"), \n",
    "               key=lambda var:[int(x) if x.isdigit() else x for x in re.findall(r'[^0-9]|[0-9]+', var)])\n",
    "    middle = len(files)//2\n",
    "    num_imgs2 = num_imgs//2\n",
    "    p1 = max(0, middle - num_imgs2)\n",
    "    p2 = min(len(files), middle + num_imgs2)\n",
    "    \n",
    "    img3d = np.stack([load_dicom_image(f, rotate=rotate) for f in files[p1:p2]]).T \n",
    "    if img3d.shape[-1] < num_imgs:\n",
    "        n_zero = np.zeros((img_size, img_size, num_imgs - img3d.shape[-1]))\n",
    "        img3d = np.concatenate((img3d,  n_zero), axis = -1)\n",
    "        \n",
    "    if np.min(img3d) < np.max(img3d):\n",
    "        img3d = img3d - np.min(img3d)\n",
    "        img3d = img3d / np.max(img3d)\n",
    "            \n",
    "    return np.expand_dims(img3d,0)\n",
    "\n",
    "\n",
    "class Dataset3D(torch.utils.data.Dataset):\n",
    "    def __init__(self, csv_path, root_path, scan_type='FLAIR', idxs=None):\n",
    "        # load df\n",
    "        df = pd.read_csv(csv_path)\n",
    "        if not idxs is None:\n",
    "            df = df.iloc[idxs]\n",
    "        # process data\n",
    "        self.data = []\n",
    "        for _, r in df.iterrows():\n",
    "            bid, label = str(r['BraTS21ID']).zfill(5), int(r['MGMT_value'])\n",
    "            self.data.append((f\"{root_path}/{bid}/{scan_type}\", label))\n",
    "        \n",
    "        del df\n",
    "        gc.collect()\n",
    "            \n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        path, label = self.data[idx]\n",
    "        \n",
    "        img = load_dicom_images_3d(path)\n",
    "        img = torch.from_numpy(np.moveaxis(img, -1, 1))\n",
    "        img = img.type(torch.float32)\n",
    "\n",
    "        return img, label\n",
    "    \n",
    "# Model, PTL wrapper\n",
    "class Custom3DNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Custom3DNet, self).__init__()\n",
    "        self.block1 = self.__gen_block(1, 64, 3, 2, 0.01)\n",
    "        self.block2 = self.__gen_block(64, 128, 3, 2, 0.02)\n",
    "        self.block3 = self.__gen_block(128, 256, 3, 2, 0.03)\n",
    "        self.block4 = self.__gen_block(256, 512, 3, 2, 0.04)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool3d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout3d(p=0.08),\n",
    "            nn.Linear(1024, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, inp):\n",
    "        x = self.block1(inp)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.block4(x)\n",
    "        #print(nn.AdaptiveAvgPool3d(1)(x).shape)\n",
    "        return self.classifier(x)\n",
    "        \n",
    "        \n",
    "    def __gen_block(self, in_channels, out_channels, kernel_size, pool_size, dropout=None):\n",
    "        layers = [\n",
    "            nn.Conv3d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool3d(kernel_size=pool_size) ,\n",
    "            nn.BatchNorm3d(num_features=out_channels)\n",
    "        ]\n",
    "        if not dropout is None:\n",
    "            layers += [nn.Dropout3d(p=dropout)]\n",
    "        return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "203b51ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-22T21:50:23.153496Z",
     "iopub.status.busy": "2021-09-22T21:50:23.152819Z",
     "iopub.status.idle": "2021-09-22T22:13:29.959713Z",
     "shell.execute_reply": "2021-09-22T22:13:29.960214Z",
     "shell.execute_reply.started": "2021-09-22T19:48:21.970167Z"
    },
    "papermill": {
     "duration": 1386.815323,
     "end_time": "2021-09-22T22:13:29.960666",
     "exception": false,
     "start_time": "2021-09-22T21:50:23.145343",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6330641508102417\n",
      "0.6106109619140625\n",
      "0.6351945797602335\n",
      "0.6213392615318298\n",
      "0.6143494844436646\n",
      "0.6348764499028524\n",
      "0.6185257434844971\n",
      "0.6493381857872009\n",
      "0.6531574924786886\n",
      "0.651016374429067\n",
      "0.48632009824117023\n",
      "0.4717064102490743\n",
      "0.4354556103547414\n",
      "0.5249312222003937\n",
      "0.5906147559483846\n",
      "0.49826517701148987\n",
      "0.6441805164019266\n",
      "0.5346886118253072\n",
      "0.48332223296165466\n",
      "0.5369014938672384\n",
      "0.5212315221627554\n",
      "0.5147817234198252\n",
      "0.551882247130076\n",
      "0.5413003961245219\n",
      "0.5180586179097494\n",
      "0.5550856987635294\n",
      "0.5923359791437784\n",
      "0.5168580810228983\n",
      "0.5512083967526754\n",
      "0.5248999496301016\n",
      "0.5442682902018229\n",
      "0.43594374259312946\n",
      "0.5326710939407349\n",
      "0.4911350707213084\n",
      "0.6478206912676493\n",
      "0.5546709299087524\n",
      "0.5104179978370667\n",
      "0.5302603046099345\n",
      "0.4984593689441681\n",
      "0.5315091411272684\n",
      "0.5129254162311554\n",
      "0.5832404295603434\n",
      "0.5109933416048685\n",
      "0.5099424719810486\n",
      "0.49676622947057086\n",
      "0.46117015679677326\n",
      "0.5201971729596456\n",
      "0.5180538296699524\n",
      "0.5143324633439382\n",
      "0.6487787961959839\n",
      "0.6325616836547852\n",
      "0.585732082525889\n",
      "0.6214184165000916\n",
      "0.6039022008577982\n",
      "0.6301645239194235\n",
      "0.6262793938318888\n",
      "0.6312978863716125\n",
      "0.6465231577555338\n",
      "0.6512830853462219\n",
      "0.6131435632705688\n",
      "0.5766544143358866\n",
      "0.5738111039002737\n",
      "0.5971359610557556\n",
      "0.559366762638092\n",
      "0.6360293825467428\n",
      "0.6216656168301901\n",
      "0.6415325403213501\n",
      "0.6176117857297262\n",
      "0.6048916776974996\n",
      "0.6301084558169047\n",
      "0.6046792070070902\n",
      "0.6415961384773254\n",
      "0.6107411980628967\n",
      "0.6357025106747946\n",
      "0.5889677405357361\n",
      "0.6186170776685079\n",
      "0.6003579298655192\n",
      "0.5992988149325053\n",
      "0.6108614206314087\n",
      "0.47193440794944763\n",
      "0.47175954778989154\n",
      "0.4684840937455495\n",
      "0.5966219107309977\n",
      "0.4774625301361084\n",
      "0.544155995051066\n",
      "0.6019032696882883\n",
      "0.6325841943422953\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    test_img_path = \"../input/rsna-miccai-brain-tumor-radiogenomic-classification/test/\"\n",
    "    submit_sub_path = '../input/rsna-miccai-brain-tumor-radiogenomic-classification/sample_submission.csv'\n",
    "    \n",
    "    models_path = [ \n",
    "        \"../input/train-3d-custom-v1-3f/0LOSS-epoch=0-val_roc_auc=0.57-val_loss=0.69.ckpt\",\n",
    "        \"../input/train-3d-custom-v1-3f/1LOSS-epoch=3-val_roc_auc=0.60-val_loss=0.68.ckpt\",\n",
    "        \"../input/train-3d-custom-v1-3f/2LOSS-epoch=4-val_roc_auc=0.54-val_loss=0.70.ckpt\"\n",
    "    ]\n",
    "    \n",
    "    # load models\n",
    "    models = []\n",
    "    for m in models_path:\n",
    "        state_dict = torch.load(m, map_location=torch.device('cpu'))['state_dict']\n",
    "        state_dict = {k.lstrip('model.'):v for k, v in state_dict.items()}\n",
    "        model = Custom3DNet()\n",
    "        model.load_state_dict(state_dict)\n",
    "        model.eval()\n",
    "        models.append(model)\n",
    "    \n",
    "    # load data\n",
    "    submit = pd.read_csv(submit_sub_path)\n",
    "    \n",
    "    # preproc. data and predict\n",
    "    preds = []\n",
    "    for i in submit['BraTS21ID'].tolist():\n",
    "        path = test_img_path + str(i).zfill(5) + '/' + 'FLAIR/'\n",
    "    \n",
    "        img = load_dicom_images_3d(path)\n",
    "        img = torch.from_numpy(np.moveaxis(img, -1, 1))\n",
    "        img = torch.unsqueeze(img, 0)\n",
    "        img = img.type(torch.float32)\n",
    "        \n",
    "        out = 0.\n",
    "        for m in models:\n",
    "            out += m(img).item()\n",
    "        print(out/3)\n",
    "        preds.append(out/3)\n",
    "\n",
    "        gc.collect()\n",
    "        \n",
    "    submit['MGMT_value'] = preds\n",
    "    submit.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f634f395",
   "metadata": {
    "papermill": {
     "duration": 0.031555,
     "end_time": "2021-09-22T22:13:30.023251",
     "exception": false,
     "start_time": "2021-09-22T22:13:29.991696",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1401.301364,
   "end_time": "2021-09-22T22:13:31.785060",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-09-22T21:50:10.483696",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
