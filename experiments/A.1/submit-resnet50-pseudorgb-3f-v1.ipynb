{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "037e909b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-09-24T19:14:15.781466Z",
     "iopub.status.busy": "2021-09-24T19:14:15.780114Z",
     "iopub.status.idle": "2021-09-24T19:14:19.439117Z",
     "shell.execute_reply": "2021-09-24T19:14:19.438345Z",
     "shell.execute_reply.started": "2021-09-24T19:10:18.835407Z"
    },
    "papermill": {
     "duration": 3.667348,
     "end_time": "2021-09-24T19:14:19.439345",
     "exception": false,
     "start_time": "2021-09-24T19:14:15.771997",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np \n",
    "import glob\n",
    "import gc\n",
    "import pandas as pd \n",
    "import pydicom as dicom\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from scipy.ndimage import zoom\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import torch \n",
    "import pytorch_lightning as pl\n",
    "import torchmetrics\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "torch.manual_seed(42)\n",
    "\n",
    "\n",
    "def load_source_dicom_line(path):\n",
    "    t_paths = sorted(\n",
    "        glob.glob(os.path.join(path, \"*\")), \n",
    "        key=lambda x: int(x[:-4].split(\"-\")[-1]),\n",
    "    )\n",
    "    images = []\n",
    "    for filename in t_paths:\n",
    "        data = dicom.read_file(filename)\n",
    "        #if data.pixel_array.max() == 0:\n",
    "        #    continue\n",
    "        images.append(data)\n",
    "        \n",
    "    return images\n",
    "\n",
    "\n",
    "def load_dicom_xyz_v2(path):\n",
    "    _3d = load_source_dicom_line(path)\n",
    "    # get metadata orientation\n",
    "    x1, y1, _, x2, y2, _ = [round(j) for j in _3d[0].ImageOrientationPatient]\n",
    "    cords = [x1, y1, x2, y2]\n",
    "    position_first, position_last = _3d[0].ImagePositionPatient, _3d[-1].ImagePositionPatient\n",
    "    # get main metadata\n",
    "    try:\n",
    "        spacing_z = np.abs(float(_3d[-1].SliceLocation) - float(_3d[0].SliceLocation)) / len(_3d)\n",
    "    except AttributeError:\n",
    "        spacing_z = np.linalg.norm(np.array(_3d[-1].ImagePositionPatient) - np.array(_3d[0].ImagePositionPatient), ord=2) / len(_3d)\n",
    "    spacing_x_y = _3d[0].PixelSpacing\n",
    "    #print(spacing_x_y)\n",
    "    #assert spacing_x_y[0] == spacing_x_y[1]\n",
    "    # form tensor\n",
    "    _3d = [np.expand_dims(i.pixel_array, axis=0) for i in _3d]\n",
    "    _3d = np.concatenate(_3d)\n",
    "    # rescale\n",
    "    _3d = zoom(_3d, (spacing_z/spacing_x_y[0], 1, 1))#first axis - rescaled\n",
    "    \n",
    "    # reorder planes if needed and rotate voxel\n",
    "    if cords == [1, 0, 0, 0]:\n",
    "        if position_first[1] < position_last[1]:\n",
    "            _3d = _3d[::-1] \n",
    "        _3d = _3d.transpose((1, 0, 2))\n",
    "        \n",
    "    elif cords == [0, 1, 0, 0]:\n",
    "        if position_first[0] < position_last[0]:\n",
    "            _3d = _3d[::-1]\n",
    "        _3d = _3d.transpose((1, 2, 0))\n",
    "        _3d = np.rot90(_3d, 2, axes=(1, 2))\n",
    "        \n",
    "    elif cords == [1, 0, 0, 1]:\n",
    "        if position_first[2] > position_last[2]:\n",
    "            _3d = _3d[::-1]\n",
    "        _3d = np.rot90(_3d, 2)\n",
    "\n",
    "    return _3d\n",
    "    \n",
    "\n",
    "def get_pseudo_rgb(img):\n",
    "    #img = np.clip(img, min_a, max_a)\n",
    "    img_nan = np.where(img == img.min(), np.nan, img)\n",
    "\n",
    "    pimages = []\n",
    "    for i in range(3):\n",
    "        # get pseudorgb shape\n",
    "        shape_2_part = list(np.nanmax(img_nan, axis=i).shape)\n",
    "        shape = [3] + shape_2_part\n",
    "        \n",
    "        prgb = np.ones(shape)\n",
    "        prgb[0, :, :] = np.nanmean(img_nan, axis=i)\n",
    "        prgb[0, :, :] /= np.nanmax(prgb[0, :, :])\n",
    "        prgb[1, :, :] = np.nanmax(img_nan, axis=i)\n",
    "        prgb[1, :, :] /= np.nanmax(prgb[1, :, :])\n",
    "        prgb[2, :, :] = np.nanstd(img_nan, axis=i)\n",
    "        prgb[2, :, :] /= np.nanmax(prgb[2, :, :])\n",
    "        \n",
    "        prgb = np.swapaxes(prgb, 0, 2)\n",
    "        prgb = np.swapaxes(prgb, 0, 1)\n",
    "        prgb = np.where(np.isnan(prgb), 0, prgb)\n",
    "        prgb = np.clip(prgb, -1, 1)\n",
    "        pimages.append(prgb)\n",
    "    \n",
    "    return pimages\n",
    "\n",
    "\n",
    "def create_pseudorgb_set(img):\n",
    "    pimgs = get_pseudo_rgb(img)\n",
    "    \n",
    "    new_pimgs = []\n",
    "    for p in pimgs:\n",
    "        # find brain bbox\n",
    "        y_shape, x_shape = p.shape[0], p.shape[1]\n",
    "        x_min, x_max, y_min, y_max = 1e3, -1, 1e3, -1 \n",
    "        for yi in range(y_shape):\n",
    "            for xi in range(x_shape):\n",
    "                if not np.sum(np.abs(p[yi, xi, :])) == 0:\n",
    "                    x_min = xi if xi < x_min else x_min\n",
    "                    y_min = yi if yi < y_min else y_min\n",
    "                    x_max = xi if xi > x_max else x_max\n",
    "                    y_max = yi if yi > y_max else y_max\n",
    "                    \n",
    "        # place in canvas\n",
    "        canvas = np.zeros((512, 512, 3))\n",
    "        x_size, y_size = x_max - x_min, y_max - y_min\n",
    "        start_x, start_y = (512-x_size)//2, (512-y_size)//2\n",
    "        canvas[start_y:start_y+y_size, start_x:start_x+x_size, :] = p[y_min:y_max, x_min:x_max, :]\n",
    "\n",
    "        new_pimgs.append(canvas.astype('float32'))\n",
    "        \n",
    "    return new_pimgs\n",
    "\n",
    "# return bottleneck and his shortcut\n",
    "class BigBottleneck(nn.Module):\n",
    "    def __init__(self, in_channels, kernels, is_shortcut=False):\n",
    "        super(BigBottleneck, self).__init__()\n",
    "        k1, k2, k3  = kernels\n",
    "        first_stride = 2 if is_shortcut else 1\n",
    "    \n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, k1, 1, first_stride, bias=False),\n",
    "            nn.BatchNorm2d(k1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        \n",
    "            nn.Conv2d(k1, k2, 3, bias=False, padding=1),\n",
    "            nn.BatchNorm2d(k2),\n",
    "            nn.ReLU(inplace=True),\n",
    "        \n",
    "            nn.Conv2d(k2, k3, 1, bias=False),\n",
    "            nn.BatchNorm2d(k3)\n",
    "        )\n",
    "    \n",
    "        self.shortcut = None\n",
    "        if is_shortcut:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, k3, 1, 2, bias=False),\n",
    "                nn.BatchNorm2d(k3)\n",
    "            )\n",
    "        else:\n",
    "            self.shortcut = nn.Identity()\n",
    "            \n",
    "        self.last_relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, inp):\n",
    "        x = self.bottleneck(inp) + self.shortcut(inp)\n",
    "        return self.last_relu(x)\n",
    "        \n",
    "        \n",
    "# resnet50 model\n",
    "class Resnet50(nn.Module):\n",
    "    def __init__(self, in_channels=3):\n",
    "        super(Resnet50, self).__init__()\n",
    "        \n",
    "        self.start = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 64, 7, stride=2, padding=3, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(3, stride=2, padding=1)\n",
    "        )\n",
    "        # 1, 2, 3, 4 layers\n",
    "        layer1 = [BigBottleneck(64, [64, 64, 256], is_shortcut=True)] + [BigBottleneck(256, [64, 64, 256]) for _ in range(1, 3)] \n",
    "        layer2 = [BigBottleneck(256, [128, 128, 512], is_shortcut=True)] + [BigBottleneck(512, [128, 128, 512]) for _ in range(1, 4)] \n",
    "        layer3 = [BigBottleneck(512, [256, 256, 1024], is_shortcut=True)] + [BigBottleneck(1024, [256, 256, 1024]) for _ in range(1, 6)] \n",
    "        layer4 = [BigBottleneck(1024, [512, 512, 2048], is_shortcut=True)] + [BigBottleneck(2048, [512, 512, 2048]) for _ in range(1, 3)]\n",
    "        layers = layer1 + layer2 + layer3 + layer4\n",
    "        self.body = nn.Sequential(*layers)\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(2048, 1000),\n",
    "            nn.Linear(1000, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, inp):\n",
    "        x = self.start(inp)\n",
    "        x = self.body(x)\n",
    "        return self.classifier(x)\n",
    "        \n",
    "        \n",
    "class LITResnet50(pl.LightningModule):\n",
    "    def __init__(self, lr=1e-5):\n",
    "        super().__init__()\n",
    "        self.lr = lr\n",
    "        self.model = Resnet50()\n",
    "        self.loss_f = nn.BCELoss()\n",
    "        self.roc_auc_f = torchmetrics.AUROC(num_classes=1)\n",
    "        self.f1_f = torchmetrics.F1()\n",
    "        self.scores = {\n",
    "            'val_loss': [],\n",
    "            'val_f1': [],\n",
    "            'val_rocauc': [],\n",
    "            'train_loss': [],\n",
    "            'train_rocauc': [],\n",
    "            'train_f1': []\n",
    "        }\n",
    "        self.first_epoch = True\n",
    "        \n",
    "        \n",
    "    def forward(self, inp):\n",
    "        return self.model(inp)\n",
    "    \n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(model.parameters(), lr=self.lr)\n",
    "\n",
    "                                \n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        x, y = train_batch\n",
    "                                \n",
    "        pred_y = self.model(x)\n",
    "        pred_y = torch.flatten(pred_y)\n",
    "        pred_y = pred_y.type(torch.float64)              \n",
    "        return self.loss_f(pred_y, y)\n",
    "    \n",
    "    \n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        x, y = train_batch\n",
    "        \n",
    "        pred_y = self.model(x)\n",
    "        pred_y = torch.flatten(pred_y)\n",
    "        pred_y = pred_y.type(torch.float64)\n",
    "                                \n",
    "        loss = self.loss_f(pred_y, y)\n",
    "        self.log(\"train_loss\", loss, on_epoch=True, logger=True)\n",
    "        \n",
    "        return {'loss': loss, 'pred': pred_y, 'y': y}\n",
    "    \n",
    "    \n",
    "    def training_epoch_end(self, outputs):\n",
    "        preds, targs = [], []\n",
    "        for out in outputs:\n",
    "            preds.append(out['pred'])\n",
    "            targs.append(out['y'])\n",
    "            \n",
    "        preds = torch.cat(tensors=preds)\n",
    "        targs = torch.cat(tensors=targs)\n",
    "        \n",
    "        rocauc = self.roc_auc_f(preds, targs.type(torch.int))\n",
    "        loss = self.loss_f(preds, targs)\n",
    "        f1 = self.f1_f(preds, targs.type(torch.int))\n",
    "        \n",
    "        self.log(\"train_roc_auc\", rocauc, logger=True, on_epoch=True)\n",
    "        \n",
    "        self.scores['train_loss'].append(loss)\n",
    "        self.scores['train_f1'].append(f1)\n",
    "        self.scores['train_rocauc'].append(rocauc)\n",
    "\n",
    "    \n",
    "    \n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        x, y = val_batch\n",
    "               \n",
    "        pred_y = self.model(x)\n",
    "        pred_y = torch.flatten(pred_y)\n",
    "        pred_y = pred_y.type(torch.float64)\n",
    "           \n",
    "        loss = self.loss_f(pred_y, y)\n",
    "        self.log(\"val_loss\", loss, on_epoch=True, logger=True)\n",
    "        \n",
    "        return {\n",
    "            'y': y, \n",
    "            'pred': pred_y\n",
    "        }\n",
    "    \n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        preds, targs = [], []\n",
    "        for out in outputs:\n",
    "            preds.append(out['pred'])\n",
    "            targs.append(out['y'])\n",
    "            \n",
    "        preds = torch.cat(tensors=preds)\n",
    "        targs = torch.cat(tensors=targs)\n",
    "        \n",
    "        rocauc = self.roc_auc_f(preds, targs.type(torch.int))\n",
    "        loss = self.loss_f(preds, targs)\n",
    "        f1 = self.f1_f(preds, targs.type(torch.int))\n",
    "        \n",
    "#         print(\"Preds shape: \", preds.shape)\n",
    "#         print(\"Targs shape: \", targs.shape)\n",
    "        \n",
    "#         print(\"rocauc ptl: \", rocauc)\n",
    "#         print(\"rocauc sklearn: \", roc_auc_score(list(map(int, torch.flatten(targs).tolist())), torch.flatten(preds).tolist()))\n",
    "        \n",
    "        self.log(\"val_roc_auc\", rocauc, logger=True, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"val_loss\", loss, logger=True, on_epoch=True, prog_bar=True)\n",
    "        if not self.first_epoch:# because method call in start training\n",
    "            self.scores['val_loss'].append(loss)\n",
    "            self.scores['val_f1'].append(f1)\n",
    "            self.scores['val_rocauc'].append(rocauc)\n",
    "        self.first_epoch = False\n",
    "   \n",
    "    \n",
    "class PseudoRGBDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, csv_path, pimgs, idxs=None):\n",
    "        # load df\n",
    "        df = pd.read_csv(csv_path)\n",
    "        if not idxs is None:\n",
    "            df = df.iloc[idxs]\n",
    "        # process data\n",
    "        self.data = []\n",
    "        for _, r in df.iterrows():\n",
    "            bid, target = r['BraTS21ID'], r['MGMT_value']\n",
    "            if pimgs[bid] == -1:\n",
    "                continue\n",
    "            self.data += [(torch.from_numpy(np.moveaxis(pimgs[bid][i], -1, 0)), float(target)) for i in range(1)]\n",
    "            gc.collect()\n",
    "                \n",
    "        del pimgs, df\n",
    "        gc.collect()\n",
    "            \n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94df3791",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-24T19:14:19.456128Z",
     "iopub.status.busy": "2021-09-24T19:14:19.454784Z",
     "iopub.status.idle": "2021-09-24T20:17:14.583624Z",
     "shell.execute_reply": "2021-09-24T20:17:14.582968Z"
    },
    "papermill": {
     "duration": 3775.140243,
     "end_time": "2021-09-24T20:17:14.583775",
     "exception": false,
     "start_time": "2021-09-24T19:14:19.443532",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5461922685305277\n",
      "0.5422345399856567\n",
      "0.5589451591173807\n",
      "0.5501331686973572\n",
      "0.5557267069816589\n",
      "0.5437542994817098\n",
      "0.5546454985936483\n",
      "0.5539363423983256\n",
      "0.5392972032229105\n",
      "0.547537644704183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:89: RuntimeWarning: All-NaN slice encountered\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:93: RuntimeWarning: Mean of empty slice\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:95: RuntimeWarning: All-NaN slice encountered\n",
      "/opt/conda/lib/python3.7/site-packages/numpy/lib/nanfunctions.py:1665: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  keepdims=keepdims)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5153825879096985\n",
      "0.5246059695879618\n",
      "0.5438394149144491\n",
      "0.515596608320872\n",
      "0.5350794593493143\n",
      "0.5222155054410299\n",
      "0.49738632639249164\n",
      "0.49118103583653766\n",
      "0.5162718097368876\n",
      "0.5125235716501871\n",
      "0.4949304560820262\n",
      "0.5119198560714722\n",
      "0.509886751572291\n",
      "0.48435888687769574\n",
      "0.4912083049615224\n",
      "0.49034929275512695\n",
      "0.49961047371228534\n",
      "0.4983927309513092\n",
      "0.48967164754867554\n",
      "0.5077093144257864\n",
      "0.5142026742299398\n",
      "0.5115422407786051\n",
      "0.5045379896958669\n",
      "0.5134802261988322\n",
      "0.535989006360372\n",
      "0.5115026632944742\n",
      "0.4996361533800761\n",
      "0.4861648579438527\n",
      "0.5087830026944479\n",
      "0.4871824085712433\n",
      "0.48706498742103577\n",
      "0.500799278418223\n",
      "0.5054487387339274\n",
      "0.5012368559837341\n",
      "0.48556403319040936\n",
      "0.541254997253418\n",
      "0.5175691246986389\n",
      "0.5441183646519979\n",
      "0.5358957250912985\n",
      "0.5457772413889567\n",
      "0.5569382508595785\n",
      "0.5433076620101929\n",
      "0.5552479028701782\n",
      "0.5461958249409994\n",
      "0.5500989754994711\n",
      "0.5494295557339987\n",
      "0.537970503171285\n",
      "0.5475536982218424\n",
      "0.5579876899719238\n",
      "0.5390849113464355\n",
      "0.5045947730541229\n",
      "0.5123843550682068\n",
      "0.5124237140019735\n",
      "0.5175414482752482\n",
      "0.5448306202888489\n",
      "0.5493161280949911\n",
      "0.5510307947794596\n",
      "0.546075721581777\n",
      "0.547957976659139\n",
      "0.5355228384335836\n",
      "0.557959775129954\n",
      "0.5492934385935465\n",
      "0.5455559293429056\n",
      "0.5489281018575033\n",
      "0.5430062413215637\n",
      "0.5559029579162598\n",
      "0.5387347539265951\n",
      "0.5583844184875488\n",
      "0.5182873606681824\n",
      "0.5396536588668823\n",
      "0.5368640621503195\n",
      "0.5503313938776652\n",
      "0.5272542834281921\n",
      "0.5399908820788065\n",
      "0.4913308024406433\n",
      "0.5356225371360779\n",
      "0.5155290563901266\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    test_img_path = \"../input/rsna-miccai-brain-tumor-radiogenomic-classification/test/\"\n",
    "    submit_sub_path = '../input/rsna-miccai-brain-tumor-radiogenomic-classification/sample_submission.csv'\n",
    "    \n",
    "    models_path = [ \n",
    "        \"../input/train-resnet50-pseudorgb-v1-3f/0LOSS-epoch=4-val_roc_auc=0.54-val_loss=0.69.ckpt\",\n",
    "        \"../input/train-resnet50-pseudorgb-v1-3f/1LOSS-epoch=0-val_roc_auc=0.42-val_loss=0.69.ckpt\",\n",
    "        \"../input/train-resnet50-pseudorgb-v1-3f/2LOSS-epoch=0-val_roc_auc=0.47-val_loss=0.69.ckpt\"\n",
    "    ]\n",
    "    \n",
    "    # load models\n",
    "    models = []\n",
    "    for m in models_path:\n",
    "        state_dict = torch.load(m, map_location=torch.device('cpu'))['state_dict']\n",
    "        state_dict = {k.lstrip('model.'):v for k, v in state_dict.items()}\n",
    "        model = Resnet50()\n",
    "        model.load_state_dict(state_dict)\n",
    "        model.eval()\n",
    "        models.append(model)\n",
    "    \n",
    "    # load data\n",
    "    submit = pd.read_csv(submit_sub_path)\n",
    "    \n",
    "    # preproc. data and predict\n",
    "    preds = []\n",
    "    for i in submit['BraTS21ID'].tolist():\n",
    "        path = test_img_path + str(i).zfill(5) + '/' + 'FLAIR/'\n",
    "        \n",
    "        img = load_dicom_xyz_v2(path)\n",
    "        inp = create_pseudorgb_set(img)\n",
    "        \n",
    "        inp = inp[0]\n",
    "        inp = torch.from_numpy(np.moveaxis(inp, -1, 0))\n",
    "        inp = torch.unsqueeze(inp, 0)\n",
    "        \n",
    "        out = 0.\n",
    "        for m in models:\n",
    "            out += m(inp).item()\n",
    "        print(out/3)\n",
    "        preds.append(out)\n",
    "        \n",
    "        gc.collect()\n",
    "        \n",
    "    submit['MGMT_value'] = preds\n",
    "    submit.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac9b3a7",
   "metadata": {
    "papermill": {
     "duration": 0.023084,
     "end_time": "2021-09-24T20:17:14.630189",
     "exception": false,
     "start_time": "2021-09-24T20:17:14.607105",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3786.936185,
   "end_time": "2021-09-24T20:17:15.905856",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-09-24T19:14:08.969671",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
