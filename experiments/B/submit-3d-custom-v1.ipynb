{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c906519d",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-09-22T19:02:26.875213Z",
     "iopub.status.busy": "2021-09-22T19:02:26.874358Z",
     "iopub.status.idle": "2021-09-22T19:02:30.060398Z",
     "shell.execute_reply": "2021-09-22T19:02:30.060777Z",
     "shell.execute_reply.started": "2021-09-22T18:54:24.134977Z"
    },
    "papermill": {
     "duration": 3.193906,
     "end_time": "2021-09-22T19:02:30.060991",
     "exception": false,
     "start_time": "2021-09-22T19:02:26.867085",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydicom \n",
    "import math\n",
    "import cv2\n",
    "import gc\n",
    "import glob\n",
    "import re\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import torchmetrics\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pydicom.pixel_data_handlers.util import apply_voi_lut\n",
    "\n",
    "IMAGE_SIZE = 256\n",
    "NUM_IMAGES = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "535281ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-22T19:02:30.072693Z",
     "iopub.status.busy": "2021-09-22T19:02:30.072051Z",
     "iopub.status.idle": "2021-09-22T19:02:30.208373Z",
     "shell.execute_reply": "2021-09-22T19:02:30.208742Z",
     "shell.execute_reply.started": "2021-09-22T18:54:28.094239Z"
    },
    "papermill": {
     "duration": 0.143477,
     "end_time": "2021-09-22T19:02:30.208871",
     "exception": false,
     "start_time": "2021-09-22T19:02:30.065394",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Functions\n",
    "\n",
    "def load_dicom_image(path, img_size=IMAGE_SIZE, voi_lut=True, rotate=0):\n",
    "    dicom = pydicom.read_file(path)\n",
    "    data = dicom.pixel_array\n",
    "    if voi_lut:\n",
    "        data = apply_voi_lut(dicom.pixel_array, dicom)\n",
    "    else:\n",
    "        data = dicom.pixel_array\n",
    "        \n",
    "    if rotate > 0:\n",
    "        rot_choices = [0, cv2.ROTATE_90_CLOCKWISE, cv2.ROTATE_90_COUNTERCLOCKWISE, cv2.ROTATE_180]\n",
    "        data = cv2.rotate(data, rot_choices[rotate])\n",
    "        \n",
    "    data = cv2.resize(data, (img_size, img_size))\n",
    "    return data\n",
    "\n",
    "\n",
    "def load_dicom_images_3d(path, num_imgs=NUM_IMAGES, img_size=IMAGE_SIZE, rotate=0):\n",
    "    files = sorted(glob.glob(f\"{path}/*.dcm\"), \n",
    "               key=lambda var:[int(x) if x.isdigit() else x for x in re.findall(r'[^0-9]|[0-9]+', var)])\n",
    "    middle = len(files)//2\n",
    "    num_imgs2 = num_imgs//2\n",
    "    p1 = max(0, middle - num_imgs2)\n",
    "    p2 = min(len(files), middle + num_imgs2)\n",
    "    \n",
    "    img3d = np.stack([load_dicom_image(f, rotate=rotate) for f in files[p1:p2]]).T \n",
    "    if img3d.shape[-1] < num_imgs:\n",
    "        n_zero = np.zeros((img_size, img_size, num_imgs - img3d.shape[-1]))\n",
    "        img3d = np.concatenate((img3d,  n_zero), axis = -1)\n",
    "        \n",
    "    if np.min(img3d) < np.max(img3d):\n",
    "        img3d = img3d - np.min(img3d)\n",
    "        img3d = img3d / np.max(img3d)\n",
    "            \n",
    "    return np.expand_dims(img3d,0)\n",
    "\n",
    "\n",
    "class Dataset3D(torch.utils.data.Dataset):\n",
    "    def __init__(self, csv_path, root_path, scan_type='FLAIR', idxs=None):\n",
    "        # load df\n",
    "        df = pd.read_csv(csv_path)\n",
    "        if not idxs is None:\n",
    "            df = df.iloc[idxs]\n",
    "        # process data\n",
    "        self.data = []\n",
    "        for _, r in df.iterrows():\n",
    "            bid, label = str(r['BraTS21ID']).zfill(5), int(r['MGMT_value'])\n",
    "            self.data.append((f\"{root_path}/{bid}/{scan_type}\", label))\n",
    "        \n",
    "        del df\n",
    "        gc.collect()\n",
    "            \n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        path, label = self.data[idx]\n",
    "        \n",
    "        img = load_dicom_images_3d(path)\n",
    "        img = torch.from_numpy(np.moveaxis(img, -1, 1))\n",
    "        img = img.type(torch.float32)\n",
    "\n",
    "        return img, label\n",
    "    \n",
    "# Model, PTL wrapper\n",
    "class Custom3DNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Custom3DNet, self).__init__()\n",
    "        self.block1 = self.__gen_block(1, 64, 3, 2, 0.01)\n",
    "        self.block2 = self.__gen_block(64, 128, 3, 2, 0.02)\n",
    "        self.block3 = self.__gen_block(128, 256, 3, 2, 0.03)\n",
    "        self.block4 = self.__gen_block(256, 512, 3, 2, 0.04)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool3d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout3d(p=0.08),\n",
    "            nn.Linear(1024, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, inp):\n",
    "        x = self.block1(inp)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.block4(x)\n",
    "        #print(nn.AdaptiveAvgPool3d(1)(x).shape)\n",
    "        return self.classifier(x)\n",
    "        \n",
    "        \n",
    "    def __gen_block(self, in_channels, out_channels, kernel_size, pool_size, dropout=None):\n",
    "        layers = [\n",
    "            nn.Conv3d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool3d(kernel_size=pool_size) ,\n",
    "            nn.BatchNorm3d(num_features=out_channels)\n",
    "        ]\n",
    "        if not dropout is None:\n",
    "            layers += [nn.Dropout3d(p=dropout)]\n",
    "        return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fd075b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-22T19:02:30.217875Z",
     "iopub.status.busy": "2021-09-22T19:02:30.217400Z",
     "iopub.status.idle": "2021-09-22T19:09:07.873242Z",
     "shell.execute_reply": "2021-09-22T19:09:07.872281Z"
    },
    "papermill": {
     "duration": 397.660976,
     "end_time": "2021-09-22T19:09:07.873450",
     "exception": false,
     "start_time": "2021-09-22T19:02:30.212474",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    test_img_path = \"../input/rsna-miccai-brain-tumor-radiogenomic-classification/test/\"\n",
    "    submit_sub_path = '../input/rsna-miccai-brain-tumor-radiogenomic-classification/sample_submission.csv'\n",
    "    model_path = \"../input/train-3d-custom-v1/ROC-epoch=15-val_roc_auc=0.63-val_loss=0.67.ckpt\"\n",
    "    \n",
    "    # loadmodel\n",
    "    state_dict = torch.load(model_path, map_location=torch.device('cpu'))['state_dict']\n",
    "    state_dict = {k.lstrip('model.'):v for k, v in state_dict.items()}\n",
    "    model = Custom3DNet()\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.eval()\n",
    "    \n",
    "    # load data\n",
    "    submit = pd.read_csv(submit_sub_path)\n",
    "    \n",
    "    # preproc. data and predict\n",
    "    preds = []\n",
    "    for i in submit['BraTS21ID'].tolist():\n",
    "        path = test_img_path + str(i).zfill(5) + '/' + 'FLAIR/'\n",
    "    \n",
    "        img = load_dicom_images_3d(path)\n",
    "        img = torch.from_numpy(np.moveaxis(img, -1, 1))\n",
    "        img = torch.unsqueeze(img, 0)\n",
    "        img = img.type(torch.float32)\n",
    "        \n",
    "        out = model(img).item()\n",
    "        preds.append(out)\n",
    "        #print(out)\n",
    "        gc.collect()\n",
    "        \n",
    "    submit['MGMT_value'] = preds\n",
    "    submit.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff3dbb8",
   "metadata": {
    "papermill": {
     "duration": 0.004908,
     "end_time": "2021-09-22T19:09:07.885327",
     "exception": false,
     "start_time": "2021-09-22T19:09:07.880419",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 407.659817,
   "end_time": "2021-09-22T19:09:08.701277",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-09-22T19:02:21.041460",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
